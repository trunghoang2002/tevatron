{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct  8 04:46:51 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:86:00.0 Off |                  Off |\n",
      "| 43%   66C    P2             392W / 450W |  22249MiB / 24564MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:AF:00.0 Off |                  Off |\n",
      "| 31%   55C    P2             121W / 450W |   5998MiB / 24564MiB |     24%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3480162      C   python                                    17984MiB |\n",
      "|    0   N/A  N/A   3695092      C   python                                     3868MiB |\n",
      "|    0   N/A  N/A   3695579      C   .../envs/env_hosting-models/bin/python      384MiB |\n",
      "|    1   N/A  N/A   3756225      C   python                                     5992MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(s) per core:                 2\n"
     ]
    }
   ],
   "source": [
    "!lscpu | grep \"Thread(s) per core\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số luồng logic: 80\n",
      "Số nhân thực: 40\n",
      "CPU có hỗ trợ siêu phân luồng (Hyper-Threading).\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Số lượng luồng logic (logical processors)\n",
    "logical_processors = psutil.cpu_count(logical=True)\n",
    "\n",
    "# Số lượng nhân thực (physical cores)\n",
    "physical_cores = psutil.cpu_count(logical=False)\n",
    "\n",
    "print(f\"Số luồng logic: {logical_processors}\")\n",
    "print(f\"Số nhân thực: {physical_cores}\")\n",
    "\n",
    "if logical_processors > physical_cores:\n",
    "    print(\"CPU có hỗ trợ siêu phân luồng (Hyper-Threading).\")\n",
    "else:\n",
    "    print(\"CPU không hỗ trợ siêu phân luồng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang\n",
      "Cloning into 'tevatron'...\n",
      "remote: Enumerating objects: 1714, done.\u001b[K\n",
      "remote: Counting objects: 100% (685/685), done.\u001b[K\n",
      "remote: Compressing objects: 100% (281/281), done.\u001b[K\n",
      "remote: Total 1714 (delta 524), reused 409 (delta 403), pack-reused 1029 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1714/1714), 20.35 MiB | 5.93 MiB/s, done.\n",
      "Resolving deltas: 100% (983/983), done.\n",
      "/home/hoang/tevatron\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang\n",
    "!git clone https://github.com/trunghoang2002/tevatron.git\n",
    "%cd tevatron\n",
    "!mkdir beir_embedding_scifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/notebooks\n"
     ]
    }
   ],
   "source": [
    "!rm -r /home/hoang/tevatron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: psutil in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from peft) (2.4.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.13.0->peft) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from pandas->datasets) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Downloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
      "Downloading accelerate-1.0.0-py3-none-any.whl (330 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading aiohttp-3.10.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.0/782.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "Downloading tokenizers-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, safetensors, regex, pyarrow, multidict, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, peft, datasets\n",
      "Successfully installed accelerate-1.0.0 aiohappyeyeballs-2.4.3 aiohttp-3.10.9 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 datasets-3.0.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.25.1 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 peft-0.13.0 pyarrow-17.0.0 pytz-2024.2 regex-2024.9.11 safetensors-0.4.5 tokenizers-0.20.0 tqdm-4.66.5 transformers-4.45.2 tzdata-2024.2 xxhash-3.5.0 yarl-1.13.1\n",
      "Collecting deepspeed\n",
      "  Downloading deepspeed-0.15.1.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (1.0.0)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from deepspeed) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from deepspeed) (24.1)\n",
      "Requirement already satisfied: psutil in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from deepspeed) (6.0.0)\n",
      "Collecting py-cpuinfo (from deepspeed)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pydantic>=2.0.0 (from deepspeed)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: torch in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from deepspeed) (2.4.1)\n",
      "Requirement already satisfied: tqdm in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from deepspeed) (4.66.5)\n",
      "Collecting nvidia-ml-py (from deepspeed)\n",
      "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pyyaml in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from accelerate) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->deepspeed)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0.0->deepspeed)\n",
      "  Downloading pydantic_core-2.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sympy in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch->deepspeed) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch->deepspeed) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch->deepspeed) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from jinja2->torch->deepspeed) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from sympy->torch->deepspeed) (1.3.0)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Downloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.15.1-py3-none-any.whl size=1483867 sha256=9821296c748c987285244be1b91c84854524bc7e85686e31af5bc57ae716a3aa\n",
      "  Stored in directory: /home/hoang/.cache/pip/wheels/f6/9c/9f/b2db425455da4c5ecd0e4ab582ef2e9cf0f6cbb36ce9f50203\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: py-cpuinfo, nvidia-ml-py, ninja, hjson, pydantic-core, annotated-types, pydantic, deepspeed\n",
      "Successfully installed annotated-types-0.7.0 deepspeed-0.15.1 hjson-3.1.0 ninja-1.11.1.1 nvidia-ml-py-12.560.30 py-cpuinfo-9.0.0 pydantic-2.9.2 pydantic-core-2.23.4\n",
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting xformers\n",
      "  Downloading xformers-0.0.28.post1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: numpy in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from xformers) (2.0.1)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from xformers) (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch==2.4.1->xformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch==2.4.1->xformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch==2.4.1->xformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch==2.4.1->xformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch==2.4.1->xformers) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from torch==2.4.1->xformers) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from jinja2->torch==2.4.1->xformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from sympy->torch==2.4.1->xformers) (1.3.0)\n",
      "Downloading faiss_gpu-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.28.post1-cp39-cp39-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu, xformers\n",
      "Successfully installed faiss-gpu-1.7.2 xformers-0.0.28.post1\n",
      "Obtaining file:///home/hoang/tevatron\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.10.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from tevatron==0.0.1) (4.45.2)\n",
      "Requirement already satisfied: datasets>=1.1.3 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from tevatron==0.0.1) (3.0.1)\n",
      "Requirement already satisfied: filelock in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (2.0.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=1.1.3->tevatron==0.0.1) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (3.10.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (0.25.1)\n",
      "Requirement already satisfied: packaging in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from datasets>=1.1.3->tevatron==0.0.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers>=4.10.0->tevatron==0.0.1) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers>=4.10.0->tevatron==0.0.1) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from transformers>=4.10.0->tevatron==0.0.1) (0.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets>=1.1.3->tevatron==0.0.1) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub>=0.22.0->datasets>=1.1.3->tevatron==0.0.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=1.1.3->tevatron==0.0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=1.1.3->tevatron==0.0.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=1.1.3->tevatron==0.0.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.32.2->datasets>=1.1.3->tevatron==0.0.1) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from pandas->datasets>=1.1.3->tevatron==0.0.1) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from pandas->datasets>=1.1.3->tevatron==0.0.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from pandas->datasets>=1.1.3->tevatron==0.0.1) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.1.3->tevatron==0.0.1) (1.16.0)\n",
      "Installing collected packages: tevatron\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of tevatron==0.0.1 from file:///home/hoang/tevatron (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for tevatron\n",
      "Successfully installed tevatron\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft\n",
    "!pip install deepspeed accelerate\n",
    "!pip install faiss-gpu xformers\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !deepspeed --include localhost:0,1 train.py \\\n",
    "#   --deepspeed ds_config.json \\\n",
    "#   --output_dir model_repllama \\\n",
    "#   --model_name_or_path meta-llama/Llama-2-7b-hf \\\n",
    "#   --save_steps 200 \\\n",
    "#   --dataset_name Tevatron/msmarco-passage \\\n",
    "#   --bf16 \\\n",
    "#   --per_device_train_batch_size 8 \\\n",
    "#   --gradient_accumulation_steps 4 \\\n",
    "#   --gradient_checkpointing \\\n",
    "#   --train_n_passages 16 \\\n",
    "#   --learning_rate 1e-4 \\\n",
    "#   --q_max_len 32 \\\n",
    "#   --p_max_len 196 \\\n",
    "#   --num_train_epochs 1 \\\n",
    "#   --logging_steps 10 \\\n",
    "#   --overwrite_output_dir \\\n",
    "#   --dataset_proc_num 4 \\\n",
    "#   --negatives_x_device \\\n",
    "#   --warmup_steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/hoang/tevatron/examples/repllama\n",
    "for s in 0 1;\n",
    "do\n",
    "CUDA_VISIBLE_DEVICES=1 python encode.py \\\n",
    "  --output_dir=temp \\\n",
    "  --model_name_or_path castorini/repllama-v1-7b-lora-passage \\\n",
    "  --tokenizer_name meta-llama/Llama-2-7b-hf \\\n",
    "  --access_token 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 \\\n",
    "  --fp16 \\\n",
    "  --per_device_eval_batch_size 1 \\\n",
    "  --passage_max_len 512 \\\n",
    "  --dataset_name Tevatron/beir-corpus \\\n",
    "  --dataset_config scifact \\\n",
    "  --dataset_split train \\\n",
    "  --dataset_proc_num 4 \\\n",
    "  --encode_output_path /kaggle/working/tevatron/beir_embedding_scifact/corpus_scifact.${s}.pkl \\\n",
    "  --dataset_number_of_shards 2 \\\n",
    "  --dataset_shard_index ${s}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.conda/envs/pytorch/lib/python3.9/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/hoang/tevatron/examples/repllama\n",
    "NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" CUDA_VISIBLE_DEVICES=1 python encode.py \\\n",
    "  --output_dir=temp \\\n",
    "  --model_name_or_path castorini/repllama-v1-7b-lora-passage \\\n",
    "  --tokenizer_name meta-llama/Llama-2-7b-hf \\\n",
    "  --access_token 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 \\\n",
    "  --fp16 \\\n",
    "  --per_device_eval_batch_size 1 \\\n",
    "  --passage_max_len 512 \\\n",
    "  --dataset_name Tevatron/beir-corpus \\\n",
    "  --dataset_config scifact \\\n",
    "  --dataset_split train \\\n",
    "  --dataset_proc_num 4 \\\n",
    "  --encode_output_path /home/hoang/tevatron/beir_embedding_scifact/corpus_scifact.${s}.pkl \\\n",
    "  --dataset_number_of_shards 2 \\\n",
    "  --dataset_shard_index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "CUDA_VISIBLE_DEVICES=1 python encode.py \\\n",
    "  --output_dir=temp \\\n",
    "  --model_name_or_path castorini/repllama-v1-7b-lora-passage \\\n",
    "  --tokenizer_name meta-llama/Llama-2-7b-hf \\\n",
    "  --access_token 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 \\\n",
    "  --fp16 \\\n",
    "  --per_device_eval_batch_size 16 \\\n",
    "  --query_max_len 512 \\\n",
    "  --dataset_name Tevatron/beir \\\n",
    "  --dataset_config scifact \\\n",
    "  --dataset_split test \\\n",
    "  --encode_output_path /home/hoang/tevatron/beir_embedding_scifact/queries_scifact.pkl \\\n",
    "  --encode_is_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "def get_model(peft_model_name):\n",
    "    config = PeftConfig.from_pretrained(peft_model_name, token=\"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\")\n",
    "    base_model = AutoModel.from_pretrained(config.base_model_name_or_path, token=\"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\")\n",
    "    model = PeftModel.from_pretrained(base_model, peft_model_name)\n",
    "    model = model.merge_and_unload()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf', token=\"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\")\n",
    "model = get_model('castorini/repllama-v1-7b-lora-passage')\n",
    "\n",
    "# Define query and passage inputs\n",
    "query = \"What is llama?\"\n",
    "title = \"Llama\"\n",
    "passage = \"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.\"\n",
    "query_input = tokenizer(f'query: {query}</s>', return_tensors='pt')\n",
    "passage_input = tokenizer(f'passage: {title} {passage}</s>', return_tensors='pt')\n",
    "\n",
    "# Run the model forward to compute embeddings and query-passage similarity score\n",
    "with torch.no_grad():\n",
    "    # compute query embedding\n",
    "    query_outputs = model(**query_input)\n",
    "    query_embedding = query_outputs.last_hidden_state[0][-1]\n",
    "    query_embedding = torch.nn.functional.normalize(query_embedding, p=2, dim=0)\n",
    "\n",
    "    # compute passage embedding\n",
    "    passage_outputs = model(**passage_input)\n",
    "    passage_embeddings = passage_outputs.last_hidden_state[0][-1]\n",
    "    passage_embeddings = torch.nn.functional.normalize(passage_embeddings, p=2, dim=0)\n",
    "\n",
    "    # compute similarity score\n",
    "    score = torch.dot(query_embedding, passage_embeddings)\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
